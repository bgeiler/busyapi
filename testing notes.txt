To get to 1 million POSTs per minute, we need 16,666 POSTs per second

Testing using Apache Bench. Saw some dropped requests in early testing using a concurrency level of 10, so tried dropping it to 9. Larger tests showed that to be unneeded; -c 50 didn't drop anything at 100k requests. Further review of the documentation suggests using -l (to ignore different length results instead of logging them as errors) should be added.

Testing of the base code shows about 3k requests per second.

Used built-in profiler to see where the code is spending time:

   ticks parent  name
  10833   56.8%  C:\WINDOWS\SYSTEM32\ntdll.dll
   5230   48.3%    LazyCompile: *Socket._writeGeneric net.js:708:42
   3628   69.4%      LazyCompile: *doWrite _stream_writable.js:379:17
   3628  100.0%        LazyCompile: *logRequest C:\Users\ben\Documents\GitHub\busyapi\node_modules\morgan\index.js:116:24
   3628  100.0%          LazyCompile: *listener C:\Users\ben\Documents\GitHub\busyapi\node_modules\on-finished\index.js:161:20
   3628  100.0%            LazyCompile: *onFinish 

Modified to remove console logging, including morgan. This tripled (!) the number of requests we can handle to about 9k/second.

Uncommented logging, redirected stdout to a file. This gave us about 7.4k/second.

Recommented logging for now (would like to find a standard logger that can do both what's coming out of morgan and console.log messages).

Implemented clustering using the built-in cluster API. Only using 3 processes for now. I have a 4-core machine and using one for Apache Bench and 3 for the server seems reasonable. Gloriously, we get up to 20k requests/sec, so we have at least gotten to the performance goal. Unless we actually care about the data store. Or logging.

The main problem now is that we now have 3 versions of the data store, one for each process. Searching around, something like Redis would be ideal if I had a good way to build it on Windows. Looks like memcached has already been ported.

Implemented memcached. Using random UUIDs for IDs and setting blindly (which is admittedly not ideal, but serviceable for the purposes of this exercise). And Apache Bench gives me... ~15.4k/second. We lost it! Quick fix, double the number of processes. I've got 8 logical processors, so this assumes 6 for the server, 1 for Apache Bench, and 1 for memcached. This gets me up to 21.8k/second, so we're back to where we need to be!

Brought back morgan using a file stream per the documentation. Seems to work OK and still gives acceptable performance. Currently about 17k/second.

Consolidated morgan and usage stats into one log by transforming the old "usages" array into a usage counter, incrementing the counter in the POST handler, and using that in a morgan format (basically just prepending the 'dev' format with usages). Gives basically the same performance as just using morgan with a file, which makes sense since we're not really doing that much extra work.